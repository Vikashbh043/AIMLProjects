Business Context: In the dynamic landscape of the media and news industry, the ability to swiftly categorize and curate content has become a strategic imperative. The vast volume of information demands efficient systems to organize and present content to the audience.

The media industry, being the pulse of information dissemination, grapples with the continuous influx of news articles spanning diverse topics. Ensuring that the right articles reach the right audience promptly is not just a logistical necessity but a critical component in retaining and engaging audiences in an age of information overload.

Common Industry Challenges: Amidst the ceaseless flow of news, organizations encounter challenges such as:

Information Overload: The sheer volume of news articles makes manual categorization impractical.
Timeliness: Delays in categorizing news articles can result in outdated or misplaced content.


Problem Definition
E-news Express, a news aggregation startup, faces the challenge of categorizing the news articles collected. With news articles covering sports, entertainment, politics, and more, the need for an advanced and automated system to categorize them has become increasingly evident. The manual efforts required for categorizing such a diverse range of news articles are substantial, and human errors in the categorization of news articles can lead to reputational damage for the startup. There is also the factor of delays and potential inaccuracies. To streamline and optimize this process, the organization recognizes the imperative of adopting cutting-edge technologies, particularly machine learning, to automate and enhance the categorization of content.

As a data scientist on the E-news Express data team, the task is to analyze the text in news articles and build an unsupervised learning model for categorizing them. The categorization done by the model can then be validated against human-defined labels to check the overall accuracy of the AI system. The goal is to optimize the categorization process, ensuring timely and personalized delivery.

Dataset Provided

Dataset - news_articles.csv
Dataset - news_articles_labels.csv with Actual lables


 Approach used to calculate embedding matrix and identify clusters:  

1. Sentence Transformer library from Hugging face was imported in the Jypter notebook to calculate embedding matrix for articles present in news_article.
2. The all-MiniLM-L6-v2 model from Sentence Transformer is an all-round (all) model trained on a large and diverse dataset of over 1 billion training samples and generates 
   state-of-the-art sentence embeddings of 384 dimensions. It is a language model (LM) that has 6 transformer encoder layers (L6) and is a smaller model (Mini) trained to mimic the performance of a larger model (BERT).
3. Calculated similarity between any query and all other encoded vectors of dataset i.e. top K similar sentences for a given query. 
4. KMeans was used to create clusters based on embedded matrix while silhoutte score was used to identify K custers which have optimal cluster performance
5. Distance between actual and predicted category was identified
